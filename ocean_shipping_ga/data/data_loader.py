"""
ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬ ëª¨ë“ˆ
"""

import pandas as pd
import numpy as np
import re
import os
from typing import Dict, Any, Optional, List
from datetime import datetime


class DataLoader:
    """
    ì—‘ì…€ íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤
    """
    
    def __init__(self, file_paths: Optional[Dict[str, str]] = None):
        """
        Parameters:
        -----------
        file_paths : dict, optional
            í•„ìš”í•œ ì—‘ì…€ íŒŒì¼ ê²½ë¡œë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
            Noneì¸ ê²½ìš° íŒ¨í‚¤ì§€ ë‚´ data í´ë”ì—ì„œ ìë™ ê²€ìƒ‰
            - 'schedule': ìŠ¤ì¼€ì¤„ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            - 'delayed': ë”œë ˆì´ ìŠ¤ì¼€ì¤„ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            - 'vessel': ì„ ë°• ë°ì´í„° íŒŒì¼ ê²½ë¡œ
            - 'port': í•­êµ¬ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        if file_paths is None:
            self.file_paths = self._get_default_file_paths()
        else:
            self.file_paths = file_paths
        self.data = {}
        
    def load_all_data(self) -> Dict[str, pd.DataFrame]:
        """ëª¨ë“  ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì •ì œ"""
        print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        self.data['schedule'] = pd.read_excel(self.file_paths['schedule'])
        self.data['delayed'] = pd.read_excel(self.file_paths['delayed'])
        
        # ì„ ë°• ë°ì´í„°ëŠ” íŠ¹ë³„í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆì–´ì„œ ìˆ˜ë™ìœ¼ë¡œ ì²˜ë¦¬
        vessel_raw = pd.read_excel(self.file_paths['vessel'])
        vessel_columns = ['ì„ ë°•ëª…', 'ìš©ëŸ‰(TEU)']
        vessel_data = vessel_raw.iloc[2:].reset_index(drop=True)  # ì²˜ìŒ 2í–‰ ê±´ë„ˆë›°ê¸°
        vessel_data.columns = vessel_columns
        self.data['vessel'] = vessel_data
        
        # í•­êµ¬ ë°ì´í„°ë„ íŠ¹ë³„í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆì–´ì„œ ìˆ˜ë™ìœ¼ë¡œ ì²˜ë¦¬
        port_raw = pd.read_excel(self.file_paths['port'])
        port_columns = ['í•­êµ¬ëª…', 'ìœ„ì¹˜_ìœ„ë„', 'ìœ„ì¹˜_ê²½ë„']
        port_data = port_raw.iloc[2:].reset_index(drop=True)  # ì²˜ìŒ 2í–‰ ê±´ë„ˆë›°ê¸°
        port_data.columns = port_columns
        self.data['port'] = port_data
        self.data['fixed'] = pd.read_excel(self.file_paths['fixed'])
        
        print(f"âœ… ìŠ¤ì¼€ì¤„ ë°ì´í„°: {len(self.data['schedule'])}ê°œ ë¡œë“œ")
        print(f"âœ… ë”œë ˆì´ ë°ì´í„°: {len(self.data['delayed'])}ê°œ ë¡œë“œ")
        print(f"âœ… ì„ ë°• ë°ì´í„°: {len(self.data['vessel'])}ê°œ ë¡œë“œ")
        print(f"âœ… í•­êµ¬ ë°ì´í„°: {len(self.data['port'])}ê°œ ë¡œë“œ")
        print(f"âœ… ê³ ì •ê°’ ë°ì´í„°: {len(self.data['fixed'])}ê°œ ë¡œë“œ")
        
        # ë°ì´í„° ì •ì œ ìˆ˜í–‰
        self._clean_datetime_columns()
        self._standardize_vessel_names()
        self._restructure_fixed_values()
        self._validate_data_integrity()
        
        print("âœ… ë°ì´í„° ì •ì œ ì™„ë£Œ")
        return self.data
    
    def parse_order_quantity(self, q: Any) -> float:
        """
        ì£¼ë¬¸ëŸ‰ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ íŒŒì‹±
        
        Parameters:
        -----------
        q : Any
            ì£¼ë¬¸ëŸ‰ ë°ì´í„° (ë¬¸ìì—´, ìˆ«ì, NaN ë“±)
            
        Returns:
        --------
        float
            íŒŒì‹±ëœ ì£¼ë¬¸ëŸ‰
        """
        try:
            if pd.isna(q):  # NaN ê°’ì¸ ê²½ìš°
                return 10000.0  # ê¸°ë³¸ê°’ ì„¤ì •
            elif isinstance(q, str):  # ë¬¸ìì—´ì¸ ê²½ìš°
                # ì •ê·œì‹ì„ ì‚¬ìš©í•´ì„œ ë¬¸ìì—´ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œ
                numbers = re.findall(r'\d+\.?\d*', str(q))
                if numbers:
                    return float(numbers[0])
                else:
                    return 10000.0  # ìˆ«ìê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’
            else:
                return float(q)  # ì´ë¯¸ ìˆ«ìì¸ ê²½ìš° ì§ì ‘ ë³€í™˜
        except (ValueError, IndexError):
            print(f"Warning: Could not parse order quantity: {q}")
            return 10000.0  # ë³€í™˜ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ê°’
    
    def get_schedule_data(self) -> pd.DataFrame:
        """ìŠ¤ì¼€ì¤„ ë°ì´í„° ë°˜í™˜"""
        return self.data.get('schedule', pd.DataFrame())
    
    def get_delayed_data(self) -> pd.DataFrame:
        """ë”œë ˆì´ ë°ì´í„° ë°˜í™˜"""
        return self.data.get('delayed', pd.DataFrame())
    
    def get_vessel_data(self) -> pd.DataFrame:
        """ì„ ë°• ë°ì´í„° ë°˜í™˜"""
        return self.data.get('vessel', pd.DataFrame())
    
    def get_port_data(self) -> pd.DataFrame:
        """í•­êµ¬ ë°ì´í„° ë°˜í™˜"""
        return self.data.get('port', pd.DataFrame())
    
    def get_fixed_data(self) -> pd.DataFrame:
        """ê³ ì •ê°’ ë°ì´í„° ë°˜í™˜"""
        return self.data.get('fixed', pd.DataFrame())
    
    def _get_default_file_paths(self) -> Dict[str, str]:
        """íŒ¨í‚¤ì§€ ë‚´ data í´ë”ì—ì„œ ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •"""
        # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ data í´ë” ê²½ë¡œ ì°¾ê¸°
        current_dir = os.path.dirname(os.path.abspath(__file__))
        
        file_paths = {
            'schedule': os.path.join(current_dir, 'ìŠ¤í•´ë¬¼_ìŠ¤ì¼€ì¤„data.xlsx'),
            'delayed': os.path.join(current_dir, 'ìŠ¤í•´ë¬¼_ë”œë ˆì´ìŠ¤ì¼€ì¤„data.xlsx'),
            'vessel': os.path.join(current_dir, 'ìŠ¤í•´ë¬¼_ì„ ë°•data.xlsx'),
            'port': os.path.join(current_dir, 'ìŠ¤í•´ë¬¼_í•­êµ¬ìœ„ì¹˜data.xlsx'),
            'fixed': os.path.join(current_dir, 'ìŠ¤í•´ë¬¼_ê³ ì •ê°’data.xlsx')
        }
        
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        for name, path in file_paths.items():
            if not os.path.exists(path):
                print(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")
                raise FileNotFoundError(f"Required data file not found: {path}")
        
        return file_paths
    
    def _clean_datetime_columns(self):
        """ë‚ ì§œ ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        datetime_columns = {
            'schedule': ['ETD', 'ETA'],
            'delayed': ['ETD', 'ETA', 'ë”œë ˆì´ ETA', ' ë”œë ˆì´ ETA']  # ê³µë°± ìˆëŠ” ê²½ìš°ë„ ì²˜ë¦¬
        }
        
        for data_type, columns in datetime_columns.items():
            if data_type in self.data:
                df = self.data[data_type]
                converted_count = 0
                
                for col in columns:
                    if col in df.columns:
                        original_type = df[col].dtype
                        try:
                            # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì‹œë„
                            df[col] = pd.to_datetime(df[col], errors='coerce', 
                                                   format=None, infer_datetime_format=True)
                            
                            # NaT ê°’ ì²´í¬
                            nat_count = df[col].isna().sum()
                            if nat_count > 0:
                                print(f"âš ï¸  {data_type}.{col}: {nat_count}ê°œ ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨")
                            else:
                                print(f"âœ… {data_type}.{col}: {original_type} â†’ datetime64")
                                converted_count += 1
                                
                        except Exception as e:
                            print(f"âŒ {data_type}.{col} ë³€í™˜ ì‹¤íŒ¨: {e}")
                
                if converted_count > 0:
                    print(f"ğŸ“… {data_type} ë°ì´í„°: {converted_count}ê°œ ë‚ ì§œ ì»¬ëŸ¼ ë³€í™˜ ì™„ë£Œ")
    
    def _standardize_vessel_names(self):
        """ì„ ë°•ëª… í‘œì¤€í™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬)"""
        vessel_columns = {
            'schedule': 'ì„ ë°•ëª…',
            'vessel': 'ì„ ë°•ëª…'
        }
        
        standardized_count = 0
        vessel_mapping = {}
        
        for data_type, column in vessel_columns.items():
            if data_type in self.data and column in self.data[data_type].columns:
                df = self.data[data_type]
                original_names = df[column].unique()
                
                # ì„ ë°•ëª… ì •ì œ í•¨ìˆ˜
                def clean_vessel_name(name):
                    if pd.isna(name):
                        return name
                    
                    # ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  ì•ë’¤ ê³µë°± ì œê±°
                    clean_name = str(name).strip()
                    
                    # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ ë³€ê²½
                    clean_name = re.sub(r'\s+', ' ', clean_name)
                    
                    # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (ë”°ì˜´í‘œ ë“±)
                    clean_name = clean_name.replace("'", "").replace('"', '')
                    
                    return clean_name
                
                # ì„ ë°•ëª… ì •ì œ ì ìš©
                df[column] = df[column].apply(clean_vessel_name)
                cleaned_names = df[column].unique()
                
                # ë³€ê²½ ì‚¬í•­ ì¶”ì 
                for orig, clean in zip(original_names, cleaned_names):
                    if orig != clean:
                        vessel_mapping[orig] = clean
                        standardized_count += 1
        
        if standardized_count > 0:
            print(f"ğŸš¢ ì„ ë°•ëª… í‘œì¤€í™”: {standardized_count}ê°œ ì„ ë°•ëª… ì •ë¦¬")
            for orig, clean in list(vessel_mapping.items())[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
                print(f"   '{orig}' â†’ '{clean}'")
        else:
            print("ğŸš¢ ì„ ë°•ëª…: ì •ë¦¬í•  í•­ëª© ì—†ìŒ")
    
    def _restructure_fixed_values(self):
        """ê³ ì •ê°’ ë°ì´í„°ë¥¼ key-value êµ¬ì¡°ë¡œ ì¬êµ¬ì„± (ë‹¨ìœ„ ê³ ë ¤)"""
        if 'fixed' not in self.data or self.data['fixed'].empty:
            print("âš ï¸  ê³ ì •ê°’ ë°ì´í„° ì—†ìŒ")
            return
        
        df = self.data['fixed']
        restructured_data = {}
        
        try:
            print(f"ğŸ”§ ê³ ì •ê°’ ë°ì´í„° íŒŒì‹± ì¤‘...")
            print(f"  - ë°ì´í„° í˜•íƒœ: {df.shape}")
            print(f"  - ì»¬ëŸ¼: {df.columns.tolist()}")
            
            # ìƒˆë¡œìš´ ì—‘ì…€ êµ¬ì¡°: ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ íŒŒë¼ë¯¸í„°ëª…, ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì´ ê°’+ë‹¨ìœ„
            for idx, row in df.iterrows():
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ í‚¤, ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì´ ê°’+ë‹¨ìœ„
                key = row.iloc[0]  # ì²« ë²ˆì§¸ ì»¬ëŸ¼
                value_with_unit = row.iloc[1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼
                
                if pd.notna(key) and pd.notna(value_with_unit):
                    # ë‹¨ìœ„ë¥¼ ê³ ë ¤í•œ ê°’ íŒŒì‹±
                    parsed_value = self._parse_value_with_unit(str(value_with_unit))
                    if parsed_value is not None:
                        restructured_data[key] = parsed_value
                        print(f"   âœ… {key}: {parsed_value} (ì›ë³¸: {value_with_unit})")
                    else:
                        print(f"   âŒ {key}: íŒŒì‹± ì‹¤íŒ¨ (ì›ë³¸: {value_with_unit})")
            
            # ì¬êµ¬ì„±ëœ ë°ì´í„° ì €ì¥
            self.data['fixed_params'] = restructured_data
            
            print(f"ğŸ’° ê³ ì •ê°’ íŒŒë¼ë¯¸í„° ì¬êµ¬ì„±: {len(restructured_data)}ê°œ í•­ëª©")
            
        except Exception as e:
            print(f"âŒ ê³ ì •ê°’ ë°ì´í„° ì¬êµ¬ì„± ì‹¤íŒ¨: {e}")
            self.data['fixed_params'] = {}
    
    def _validate_data_integrity(self):
        """ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦"""
        print("\nğŸ” ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦:")
        
        # 1. ì„ ë°•ëª… ì¼ì¹˜ ê²€ì¦
        schedule_vessels = set(self.data['schedule']['ì„ ë°•ëª…'].dropna())
        vessel_names = set(self.data['vessel']['ì„ ë°•ëª…'].dropna())
        
        missing_vessels = schedule_vessels - vessel_names
        if missing_vessels:
            print(f"âš ï¸  ìŠ¤ì¼€ì¤„ì— ìˆì§€ë§Œ ì„ ë°• ë°ì´í„°ì— ì—†ëŠ” ì„ ë°•: {len(missing_vessels)}ê°œ")
            for vessel in list(missing_vessels)[:3]:
                print(f"     - {vessel}")
        else:
            print("âœ… ì„ ë°•ëª… ì¼ì¹˜: ëª¨ë“  ìŠ¤ì¼€ì¤„ ì„ ë°•ì´ ì„ ë°• ë°ì´í„°ì— ì¡´ì¬")
        
        # 2. ë”œë ˆì´ ìŠ¤ì¼€ì¤„ ì¼ì¹˜ ê²€ì¦
        schedule_ids = set(self.data['schedule']['ìŠ¤ì¼€ì¤„ ë²ˆí˜¸'].dropna())
        delayed_ids = set(self.data['delayed']['ìŠ¤ì¼€ì¤„ ë²ˆí˜¸'].dropna())
        
        invalid_delays = delayed_ids - schedule_ids
        if invalid_delays:
            print(f"âš ï¸  ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìŠ¤ì¼€ì¤„ì˜ ë”œë ˆì´: {len(invalid_delays)}ê°œ")
        else:
            print("âœ… ë”œë ˆì´ ìŠ¤ì¼€ì¤„ ì¼ì¹˜: ëª¨ë“  ë”œë ˆì´ê°€ ìœ íš¨í•œ ìŠ¤ì¼€ì¤„")
        
        # 3. í•­êµ¬ëª… ì¼ì¹˜ ê²€ì¦
        schedule_ports = set(self.data['schedule']['ì¶œë°œí•­'].dropna()) | set(self.data['schedule']['ë„ì°©í•­'].dropna())
        port_names = set(self.data['port']['í•­êµ¬ëª…'].dropna())
        
        missing_ports = schedule_ports - port_names
        if missing_ports:
            print(f"âš ï¸  ìŠ¤ì¼€ì¤„ì— ìˆì§€ë§Œ í•­êµ¬ ë°ì´í„°ì— ì—†ëŠ” í•­êµ¬: {len(missing_ports)}ê°œ")
            for port in missing_ports:
                print(f"     - {port}")
        else:
            print("âœ… í•­êµ¬ëª… ì¼ì¹˜: ëª¨ë“  ìŠ¤ì¼€ì¤„ í•­êµ¬ê°€ í•­êµ¬ ë°ì´í„°ì— ì¡´ì¬")
        
        # 4. ë‚ ì§œ ìœ íš¨ì„± ê²€ì¦
        if 'ETA' in self.data['schedule'].columns and 'ETD' in self.data['schedule'].columns:
            invalid_dates = (self.data['schedule']['ETA'] <= self.data['schedule']['ETD']).sum()
            if invalid_dates > 0:
                print(f"âš ï¸  ETAê°€ ETDë³´ë‹¤ ë¹ ë¥¸ ìŠ¤ì¼€ì¤„: {invalid_dates}ê°œ")
            else:
                print("âœ… ë‚ ì§œ ìˆœì„œ: ETA > ETD ì¡°ê±´ ë§Œì¡±")
    
    def get_fixed_params(self) -> Dict[str, float]:
        """ì¬êµ¬ì„±ëœ ê³ ì •ê°’ íŒŒë¼ë¯¸í„° ë°˜í™˜"""
        return self.data.get('fixed_params', {})
    
    def _parse_value_with_unit(self, value_with_unit: str) -> Optional[float]:
        """
        ë‹¨ìœ„ê°€ í¬í•¨ëœ ê°’ì„ íŒŒì‹±í•˜ì—¬ ìˆ«ìë¡œ ë³€í™˜
        
        Parameters:
        -----------
        value_with_unit : str
            ë‹¨ìœ„ê°€ í¬í•¨ëœ ê°’ (ì˜ˆ: "100 USD/TEU", "150 USD/DAY")
            
        Returns:
        --------
        Optional[float]
            íŒŒì‹±ëœ ìˆ«ì ê°’, ì‹¤íŒ¨ ì‹œ None
        """
        try:
            # ê³µë°± ì œê±° ë° ëŒ€ë¬¸ì ë³€í™˜
            value_with_unit = value_with_unit.strip().upper()
            
            # ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
            import re
            numbers = re.findall(r'\d+\.?\d*', value_with_unit)
            if not numbers:
                return None
            
            base_value = float(numbers[0])
            
            # ë‹¨ìœ„ë³„ ë³€í™˜
            if 'USD/TEU' in value_with_unit:
                # TEU ë‹¨ìœ„ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
                return base_value
            elif 'USD/FEU' in value_with_unit:
                # FEUë¥¼ TEUë¡œ ë³€í™˜ (FEU = 2 TEU)
                return base_value / 2
            elif 'USD/DAY' in value_with_unit or 'USD/ì¼' in value_with_unit:
                # ì¼ì¼ ë‹¨ìœ„ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš©
                return base_value
            elif 'USD' in value_with_unit:
                # USDë§Œ ìˆëŠ” ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬
                return base_value
            elif 'KG' in value_with_unit or 'KG/TEU' in value_with_unit:
                # KG ë‹¨ìœ„ëŠ” ê·¸ëŒ€ë¡œ ì‚¬ìš© (TEU ë³€í™˜ ê¸°ì¤€)
                return base_value
            else:
                # ë‹¨ìœ„ê°€ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš° ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ë¦¬
                print(f"     âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” ë‹¨ìœ„: {value_with_unit}")
                return base_value
                
        except Exception as e:
            print(f"     âŒ ê°’ íŒŒì‹± ì˜¤ë¥˜: {value_with_unit} - {e}")
            return None